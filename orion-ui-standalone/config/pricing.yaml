# ──────────────────────────────────────────────────────────
#  Orion Forge — LLM Pricing Registry
# ──────────────────────────────────────────────────────────
#
#  All prices are in USD per 1 million tokens.
#  Four cost dimensions per model:
#    input_per_1m        — standard input tokens
#    cached_input_per_1m — input tokens served from provider cache
#    output_per_1m       — output / completion tokens
#    training_per_1m     — fine-tuning / training tokens (if applicable)
#
#  Lookup order (see metering.py):
#    1. Exact model name match
#    2. Prefix match (e.g. "gpt-4o" matches "gpt-4o-2025-01-01")
#    3. Provider "_default" fallback
#    4. Zero cost (unknown model)
#
#  This file is auto-managed by the Pricing page UI.
#  Manual edits are safe — the UI merges, never overwrites blindly.
# ──────────────────────────────────────────────────────────

openai:
  _default:
    input_per_1m: 2.50
    cached_input_per_1m: 1.25
    output_per_1m: 10.00
    training_per_1m: 0.00

  gpt-4o:
    input_per_1m: 2.50
    cached_input_per_1m: 1.25
    output_per_1m: 10.00
    training_per_1m: 25.00

  gpt-4o-mini:
    input_per_1m: 0.15
    cached_input_per_1m: 0.075
    output_per_1m: 0.60
    training_per_1m: 0.30

  gpt-4.1:
    input_per_1m: 2.00
    cached_input_per_1m: 0.50
    output_per_1m: 8.00
    training_per_1m: 0.00

  gpt-4.1-mini:
    input_per_1m: 0.40
    cached_input_per_1m: 0.10
    output_per_1m: 1.60
    training_per_1m: 0.00

  gpt-4.1-nano:
    input_per_1m: 0.10
    cached_input_per_1m: 0.025
    output_per_1m: 0.40
    training_per_1m: 0.00

  gpt-5.1:
    input_per_1m: 5.00
    cached_input_per_1m: 1.25
    output_per_1m: 15.00
    training_per_1m: 0.00

  o1:
    input_per_1m: 15.00
    cached_input_per_1m: 7.50
    output_per_1m: 60.00
    training_per_1m: 0.00

  o1-mini:
    input_per_1m: 1.10
    cached_input_per_1m: 0.55
    output_per_1m: 4.40
    training_per_1m: 0.00

  o3:
    input_per_1m: 10.00
    cached_input_per_1m: 2.50
    output_per_1m: 40.00
    training_per_1m: 0.00

  o3-mini:
    input_per_1m: 1.10
    cached_input_per_1m: 0.55
    output_per_1m: 4.40
    training_per_1m: 0.00

  o4-mini:
    input_per_1m: 1.10
    cached_input_per_1m: 0.275
    output_per_1m: 4.40
    training_per_1m: 0.00

anthropic:
  _default:
    input_per_1m: 3.00
    cached_input_per_1m: 0.30
    output_per_1m: 15.00
    training_per_1m: 0.00

  claude-sonnet-4-20250514:
    input_per_1m: 3.00
    cached_input_per_1m: 0.30
    output_per_1m: 15.00
    training_per_1m: 0.00

  claude-3.5-sonnet:
    input_per_1m: 3.00
    cached_input_per_1m: 0.30
    output_per_1m: 15.00
    training_per_1m: 0.00

  claude-3-haiku:
    input_per_1m: 0.25
    cached_input_per_1m: 0.03
    output_per_1m: 1.25
    training_per_1m: 0.00

  claude-3-opus:
    input_per_1m: 15.00
    cached_input_per_1m: 1.50
    output_per_1m: 75.00
    training_per_1m: 0.00

  claude-opus-4-20250514:
    input_per_1m: 15.00
    cached_input_per_1m: 1.50
    output_per_1m: 75.00
    training_per_1m: 0.00

deepseek:
  _default:
    input_per_1m: 0.14
    cached_input_per_1m: 0.014
    output_per_1m: 0.28
    training_per_1m: 0.00

  deepseek-chat:
    input_per_1m: 0.14
    cached_input_per_1m: 0.014
    output_per_1m: 0.28
    training_per_1m: 0.00

  deepseek-reasoner:
    input_per_1m: 0.55
    cached_input_per_1m: 0.14
    output_per_1m: 2.19
    training_per_1m: 0.00

ollama:
  _default:
    input_per_1m: 0.00
    cached_input_per_1m: 0.00
    output_per_1m: 0.00
    training_per_1m: 0.00
